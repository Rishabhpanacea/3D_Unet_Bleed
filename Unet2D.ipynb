{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7241696b-fcc0-4f1f-9571-8ffa340db267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Models.D_UNet import UNet2D, ResidualUNet2D\n",
    "from src.utils.losses import BCEDiceLoss, DiceLoss, GeneralizedDiceLoss, WeightedCrossEntropyLoss, WeightedSmoothL1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b15bf4-e2ad-408f-a698-59b4b12f1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset3D(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, datadict=datadict,  output_size=(256, 256), output_depth=5):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        self.series = os.listdir(mask_dir)\n",
    "        self.datadict = datadict\n",
    "        reversed_dict = {v: k for k, v in datadict.items()}\n",
    "        self.reversed_dict = reversed_dict\n",
    "\n",
    "        self.output_size = (IMAGE_HEIGHT, IMAGE_WIDTH)  # (H, W)\n",
    "        self.output_depth = output_depth  # New Depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Maskvolume = []\n",
    "        ImageVolume = []\n",
    "        # print(self.series[index])\n",
    "        flag = 0\n",
    "        for key in range(len(self.reversed_dict.keys())):\n",
    "            catag = self.reversed_dict[key]\n",
    "            Maskcatgvolume = []\n",
    "            Masks = os.path.join(self.mask_dir, os.listdir(self.mask_dir)[index], catag)\n",
    "            MasksList = os.listdir(Masks)\n",
    "            MasksList = sorted(MasksList)\n",
    "            \n",
    "            for msk in MasksList:\n",
    "                pngMask = Image.open(os.path.join(Masks, msk))\n",
    "                pngMask = np.array(pngMask)\n",
    "                Maskcatgvolume.append(pngMask)\n",
    "    \n",
    "                if msk in self.images and flag == 0:\n",
    "                    pngimage = Image.open(os.path.join(self.image_dir ,msk))\n",
    "                    pngimage = np.array(pngimage)\n",
    "                    ImageVolume.append(pngimage)\n",
    "            flag = 1\n",
    "                    \n",
    "            Maskcatgvolume = np.stack(Maskcatgvolume, axis = 0)\n",
    "            Maskvolume.append(Maskcatgvolume)\n",
    "            \n",
    "        Maskvolume = np.stack(Maskvolume, axis = 0)\n",
    "        ImageVolume = np.stack(ImageVolume, axis = 0)\n",
    "        ImageVolume = np.expand_dims(ImageVolume, axis=0)\n",
    "        newMaskVolume = []\n",
    "        for i in range(Maskvolume.shape[1]):\n",
    "            newMaskVolume.append(np.argmax(Maskvolume[:,i,:,:] , axis=0))\n",
    "        newMaskVolume = np.stack(newMaskVolume, axis=0)\n",
    "        newMaskVolume = np.expand_dims(newMaskVolume, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        resized_images = np.array([cv2.resize(img, self.output_size, interpolation=cv2.INTER_LINEAR) for img in ImageVolume[0]])\n",
    "        resized_masks = np.array([cv2.resize(mask, self.output_size, interpolation=cv2.INTER_NEAREST) for mask in newMaskVolume[0]])\n",
    "\n",
    "        # print('resized_images:-',resized_images.shape)\n",
    "        # print('resized_masks:-',resized_masks.shape)\n",
    "        # print(np.unique(resized_images))\n",
    "\n",
    "\n",
    "        new_images = []\n",
    "        new_masks = []\n",
    "        if self.transform is not None:\n",
    "            for slic in range(resized_images.shape[0]):\n",
    "                image = resized_images[slic,:,:]\n",
    "                mask = resized_masks[slic,:,:]\n",
    "\n",
    "                augmentations = self.transform(image=image, mask=mask)\n",
    "                image = augmentations[\"image\"].squeeze(0)\n",
    "                mask = augmentations[\"mask\"].squeeze(0)\n",
    "                new_images.append(image)\n",
    "                new_masks.append(mask)\n",
    "        \n",
    "        return torch.stack(new_images).unsqueeze(0), torch.stack(new_masks).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10532e5-f4ad-4381-99f3-2f5155765b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = [16, 32, 64, 128, 256, 512, 1024]\n",
    "for i in range(len(f)):\n",
    "    model = UNet2D(in_channels=1, out_channels=9, f_maps=f[i])\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total Parameters {f[i]}: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f82c35-b992-420f-b8e4-91d33d028e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.configuration.config import datadict\n",
    "Dir = r\"C:\\Users\\Rishabh\\Documents\\pytorch-3dunet\\TrainingData\"\n",
    "image_dir = os.path.join(Dir, 'Images')\n",
    "mask_dir = os.path.join(Dir, 'Masks')\n",
    "images = os.listdir(image_dir)\n",
    "series = os.listdir(mask_dir)\n",
    "datadict = datadict\n",
    "reversed_dict = {v: k for k, v in datadict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5b5c36-0c4e-4db0-b1f2-e3e095bde396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "index = 3\n",
    "Maskvolume = []\n",
    "ImageVolume = []\n",
    "flag = 0\n",
    "for key in range(len(reversed_dict.keys())):\n",
    "    catag = reversed_dict[key]\n",
    "    Maskcatgvolume = []\n",
    "    Masks = os.path.join(mask_dir, os.listdir(mask_dir)[index], catag)\n",
    "    MasksList = os.listdir(Masks)\n",
    "    MasksList = sorted(MasksList)\n",
    "    \n",
    "    for msk in MasksList:\n",
    "        pngMask = Image.open(os.path.join(Masks, msk))\n",
    "        pngMask = np.array(pngMask)\n",
    "        Maskcatgvolume.append(pngMask)\n",
    "\n",
    "        if msk in images and flag == 0:\n",
    "            pngimage = Image.open(os.path.join(image_dir ,msk))\n",
    "            pngimage = np.array(pngimage)\n",
    "            ImageVolume.append(pngimage)\n",
    "    flag = 1\n",
    "            \n",
    "    Maskcatgvolume = np.stack(Maskcatgvolume, axis = 0)\n",
    "    Maskvolume.append(Maskcatgvolume)\n",
    "    \n",
    "Maskvolume = np.stack(Maskvolume, axis = 0)\n",
    "ImageVolume = np.stack(ImageVolume, axis = 0)\n",
    "\n",
    "newMaskVolume = []\n",
    "for i in range(Maskvolume.shape[1]):\n",
    "    newMaskVolume.append(np.argmax(Maskvolume[:,i,:,:] , axis=0))\n",
    "newMaskVolume = np.stack(newMaskVolume, axis=0)\n",
    "\n",
    "newMaskVolume[newMaskVolume>0] = -1\n",
    "newMaskVolume[newMaskVolume == 0] = 1\n",
    "newMaskVolume[newMaskVolume == -1] = 0\n",
    "\n",
    "for i in range(Maskvolume.shape[1]):\n",
    "    Maskvolume[0,i,:,:] = Maskvolume[0,i,:,:] + newMaskVolume[i,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d11a66-5659-42ed-9050-f23fed926e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maskvolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ecae8-5926-4250-8cb3-49b7a0d51475",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maskvolume[1:,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948061e-b4b4-4faf-b578-838ef0be1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume[:3,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff64f2d-45da-48bf-8b45-8ee7e8c32ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ImageVolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c93ccff-11c9-494f-9d36-1ff9b8bdc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = ImageVolume[:3,:,:]\n",
    "inputs = inputs/255\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "inputs = inputs.unsqueeze(0)\n",
    "inputs = inputs.to(device)\n",
    "targets = Maskvolume[:,1,:,:]\n",
    "targets = torch.tensor(targets, dtype=torch.float32)\n",
    "targets = targets.unsqueeze(0)\n",
    "targets = targets.to(device)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6fa04-b0e2-4341-acd2-d6f79e025b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2D(in_channels=3, out_channels=9, f_maps=128).to(device)\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6de83-ca72-46d8-a041-6e7e4106659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd434f5-a5c2-422f-8ea8-cd489749f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a6c6f-790f-4154-89cd-4f83f893579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4427c-7782-432e-b5cf-c196c4ed2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lossfn(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4733ffc-9c64-4e7e-bd70-57dfa45a8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_25204\\1069884625.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "model = UNet2D(in_channels=3, out_channels=9, f_maps=128).to(device)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# lossfn = DiceLoss()\n",
    "lossfn = nn.BCEWithLogitsLoss()\n",
    "# lossfn = BCEDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6376ff40-4374-42da-b469-d6ecdbbb6f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_25204\\221884028.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[32m     17\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m scaler.update()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# if i%100 == 0:\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#     print(loss.item())\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(10000):\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass with mixed precisio/n\n",
    "    with torch.cuda.amp.autocast():\n",
    "        outputs = model(inputs)\n",
    "        loss = lossfn(outputs, targets)\n",
    "        print(loss.item())\n",
    "\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    \n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # if i%100 == 0:\n",
    "    #     print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b2af4-1349-4f0d-ba72-f6488ca39749",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(targets.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901f0ba-bd84-4716-9571-0e9236745c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(outputs.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ef157-ef59-46ac-ae12-23fa11e63bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def dice_loss(preds, targets, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the Dice Loss.\n",
    "    \n",
    "    Args:\n",
    "        preds (torch.Tensor): Model predictions (logits or probabilities) with shape (N, C, H, W) or (N, C).\n",
    "        targets (torch.Tensor): Ground truth labels with the same shape as preds.\n",
    "        smooth (float): Smoothing factor to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Dice loss value.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds)  # Ensure predictions are in [0, 1] if logits are provided\n",
    "    \n",
    "    intersection = torch.sum(preds * targets, dim=(1, 2, 3))\n",
    "    union = torch.sum(preds, dim=(1, 2, 3)) + torch.sum(targets, dim=(1, 2, 3))\n",
    "    \n",
    "    dice_score = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return 1 - dice_score.mean()\n",
    "\n",
    "# Example usage:\n",
    "preds = torch.randn(4, 1, 256, 256)  # Example tensor with batch size 4\n",
    "targets = torch.randint(0, 2, (4, 1, 256, 256)).float()\n",
    "\n",
    "loss = dice_loss(preds, targets)\n",
    "print(\"Dice Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0870b64-b32d-498b-bb74-479cc861d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.randn(2, 9, 256, 256)  # Example tensor with batch size 4\n",
    "targets = torch.randint(0, 11, (2, 9, 256, 256)).float()\n",
    "lossfn = GeneralizedDiceLoss()\n",
    "# lossfn = WeightedCrossEntropyLoss()\n",
    "# loss = dice_loss(targets, targets)\n",
    "loss = lossfn(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe200d4-5e05-4abc-961c-c11e89d97db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6550771-25a8-42d6-9fcb-d1dcb7db416c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
