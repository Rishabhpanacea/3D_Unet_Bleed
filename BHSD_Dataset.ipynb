{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccd5911-f1d5-4edf-bbd6-f8193bb407d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ef9d93-f0a3-4020-908b-551956ff1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = r\"C:\\Users\\Rishabh\\Downloads\\label_192\\label_192\"\n",
    "ground_truths = os.path.join(Dir, 'ground truths')\n",
    "images = os.path.join(Dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfce1393-151c-4f47-93b1-cc6197bfbe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Rishabh\\\\Downloads\\\\label_192\\\\label_192\\\\images'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f699113-d7b6-4ec4-9c22-9c09a2c76340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Rishabh\\\\Downloads\\\\label_192\\\\label_192\\\\ground truths'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd05b65-1d32-49a3-aafc-a0606821e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8050e50-534c-4b40-a658-677fcf78f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d829159e-480a-4aee-9203-148d9e449ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 3.]\n",
      "[0. 2. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 1. 2. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 3. 4.]\n",
      "[0. 2.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3.]\n",
      "[0. 2. 4.]\n",
      "[0. 5.]\n",
      "[0. 2.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 1.]\n",
      "[0. 4. 5.]\n",
      "[0. 1. 4.]\n",
      "[0. 5.]\n",
      "[0. 1. 4.]\n",
      "[0. 1. 4.]\n",
      "[0. 1. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 4.]\n",
      "[0. 1. 2. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3.]\n",
      "[0. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 1. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 1.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 4.]\n",
      "[0. 4.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2.]\n",
      "[0. 1. 2. 3. 4.]\n",
      "[0. 1.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 1.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 4.]\n",
      "[0. 4.]\n",
      "[0. 2.]\n",
      "[0. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 4. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 1.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 1.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 4.]\n",
      "[0. 2. 4.]\n",
      "[0. 2.]\n",
      "[0. 1. 5.]\n",
      "[0. 1. 2. 4. 5.]\n",
      "[0. 2. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 2.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 4.]\n",
      "[0. 3.]\n",
      "[0. 3. 4.]\n",
      "[0. 3. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 2.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3.]\n",
      "[0. 2. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 1.]\n",
      "[0. 2. 3.]\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "[0. 3.]\n",
      "[0. 4.]\n",
      "[0. 5.]\n",
      "[0. 2.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2.]\n",
      "[0. 1. 2. 3. 4.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 4. 5.]\n",
      "[0. 5.]\n",
      "[0. 2. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 3.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 3. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 4.]\n",
      "[0. 4.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 2. 3.]\n",
      "[0. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 3. 4.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 3. 4.]\n",
      "[0. 4.]\n",
      "[0. 5.]\n",
      "[0. 2. 3. 4. 5.]\n",
      "[0. 2. 4. 5.]\n",
      "[0. 3. 4. 5.]\n",
      "[0. 4.]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Load the NIfTI file\n",
    "for index in range(len(os.listdir(images))):\n",
    "    nii_segementation = nib.load(os.path.join(ground_truths, os.listdir(images)[index]))\n",
    "    nii_image = nib.load(os.path.join(images, os.listdir(images)[index]))\n",
    "    \n",
    "    # Get the image data as a NumPy array\n",
    "    image_data = nii_image.get_fdata()\n",
    "    segementation_data = nii_segementation.get_fdata()\n",
    "    # print(image_data.shape,'  ',segementation_data.shape)\n",
    "    print(np.unique(segementation_data))\n",
    "    # if image_data.shape != segementation_data.shape:\n",
    "    #     print(\"wrong\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f49f568-68ca-4461-9822-e35107f5478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "nii_segementation = nib.load(os.path.join(ground_truths, os.listdir(images)[index]))\n",
    "nii_image = nib.load(os.path.join(images, os.listdir(images)[index]))\n",
    "\n",
    "# Get the image data as a NumPy array\n",
    "image_data = nii_image.get_fdata()\n",
    "segementation_data = nii_segementation.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f9bea6c-0d2a-48bc-a06c-7faa2e9e0898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10181fcb-c1b2-4ad9-a117-7c6ea3a1eb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segementation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28cfee92-bee8-4dfd-9cc0-b2b3cc144aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0.]\n",
      "1     [0.]\n",
      "2     [0.]\n",
      "3     [0.]\n",
      "4     [0.]\n",
      "5     [0.]\n",
      "6     [0. 1.]\n",
      "7     [0. 1.]\n",
      "8     [0. 1.]\n",
      "9     [0. 1.]\n",
      "10     [0. 1.]\n",
      "11     [0. 1.]\n",
      "12     [0.]\n",
      "13     [0.]\n",
      "14     [0.]\n",
      "15     [0.]\n",
      "16     [0.]\n",
      "17     [0.]\n",
      "18     [0.]\n",
      "19     [0.]\n",
      "20     [0.]\n",
      "21     [0.]\n",
      "22     [0.]\n",
      "23     [0.]\n",
      "24     [0.]\n",
      "25     [0.]\n",
      "26     [0.]\n",
      "27     [0.]\n",
      "28     [0.]\n",
      "29     [0.]\n",
      "30     [0.]\n",
      "31     [0.]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "for slice_index in range(segementation_data.shape[2]): \n",
    "    print(slice_index, '   ', np.unique(segementation_data[:,:,slice_index]))\n",
    "    # image_slice = Image.fromarray(image_data[:,:,slice_index])\n",
    "    # segementation_slice = Image.fromarray(segementation_data[:,:,slice_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3437ed24-c786-4cb2-ba17-ad761f41d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slice.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d95e70c-79e5-4f0b-9eb2-b022e9005199",
   "metadata": {},
   "outputs": [],
   "source": [
    "segementation_slice.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1d4b179-dbed-457f-9c08-e317826dd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_index = 7\n",
    "image_slice = Image.fromarray(image_data[:,:,slice_index])\n",
    "segementation_slice = Image.fromarray(segementation_data[:,:,slice_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de30b2-eab4-4f1e-baba-b0871aa4cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from src.configuration.config import datadict\n",
    "newDatadict = {'BackGround': 0,\n",
    " 'Bleed-Subdural': 1,\n",
    " 'Scalp-Hematoma': 2,\n",
    " 'Bleed-Others': 3,\n",
    " 'Bleed-Intraventricular': 4,\n",
    " 'Bleed-Epidural': 5,\n",
    "}\n",
    "\n",
    "class CustomDataset2D(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, datadict=newDatadict):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        self.series = os.listdir(mask_dir)\n",
    "        self.datadict = datadict\n",
    "        reversed_dict = {v: k for k, v in datadict.items()}\n",
    "        self.reversed_dict = reversed_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for i in range(len(self.series)):\n",
    "            first_folder = os.listdir(os.path.join(self.mask_dir, self.series[i]))[0]\n",
    "            folder_path = os.path.join(self.mask_dir, self.series[i], first_folder)\n",
    "            series_length = len(os.listdir(folder_path))\n",
    "            count = count + series_length\n",
    "        return count\n",
    "\n",
    "\n",
    "    def transform_volume(self, image_volume, mask_volume):\n",
    "        transformed = self.transform(\n",
    "                image=image_volume.transpose(1, 2, 0), \n",
    "                mask=mask_volume.transpose(1, 2, 0)  # Change (9, 512, 512) -> (512, 512, 9)\n",
    "            )\n",
    "        images = transformed['image']\n",
    "        masks = transformed['mask'].permute(2, 0, 1)\n",
    "        return images , masks\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        count = 0\n",
    "        index = index + 1\n",
    "        for i in range(len(self.series)):\n",
    "            first_folder = os.listdir(os.path.join(self.mask_dir, self.series[i]))[0]\n",
    "            folder_path = os.path.join(self.mask_dir, self.series[i], first_folder)\n",
    "            series_length = len(os.listdir(folder_path))\n",
    "\n",
    "            if count+series_length > index:\n",
    "                self.series_index = i\n",
    "                index = index-count-1\n",
    "                break\n",
    "            elif count+series_length == index:\n",
    "                self.series_index = i\n",
    "                index = series_length - 1\n",
    "                break\n",
    "            else:\n",
    "                count = count + series_length\n",
    "            \n",
    "        Maskvolume = []\n",
    "        ImageVolume = []\n",
    "        flag = 0\n",
    "        for key in range(len(self.reversed_dict.keys())):\n",
    "            catag = self.reversed_dict[key]\n",
    "            Maskcatgvolume = []\n",
    "            Masks = os.path.join(self.mask_dir, os.listdir(self.mask_dir)[self.series_index], catag)\n",
    "            MasksList = os.listdir(Masks)\n",
    "            MasksList = sorted(MasksList)\n",
    "            \n",
    "            for msk in MasksList:\n",
    "                pngMask = Image.open(os.path.join(Masks, msk))\n",
    "                pngMask = np.array(pngMask)\n",
    "                Maskcatgvolume.append(pngMask)\n",
    "        \n",
    "                if msk in self.images and flag == 0:\n",
    "                    pngimage = Image.open(os.path.join(self.image_dir ,msk))\n",
    "                    pngimage = np.array(pngimage)\n",
    "                    ImageVolume.append(pngimage)\n",
    "            flag = 1\n",
    "                    \n",
    "            Maskcatgvolume = np.stack(Maskcatgvolume, axis = 0)\n",
    "            Maskvolume.append(Maskcatgvolume)\n",
    "            \n",
    "        Maskvolume = np.stack(Maskvolume, axis = 0)\n",
    "        ImageVolume = np.stack(ImageVolume, axis = 0)\n",
    "        \n",
    "        newMaskVolume = []\n",
    "        for i in range(Maskvolume.shape[1]):\n",
    "            newMaskVolume.append(np.argmax(Maskvolume[:,i,:,:] , axis=0))\n",
    "        newMaskVolume = np.stack(newMaskVolume, axis=0)\n",
    "        \n",
    "        newMaskVolume[newMaskVolume>0] = -1\n",
    "        newMaskVolume[newMaskVolume == 0] = 1\n",
    "        newMaskVolume[newMaskVolume == -1] = 0\n",
    "        \n",
    "        for i in range(Maskvolume.shape[1]):\n",
    "            Maskvolume[0,i,:,:] = Maskvolume[0,i,:,:] + newMaskVolume[i,:,:]\n",
    "\n",
    "\n",
    "        newImageVolume = []\n",
    "        newMaskVolume = []\n",
    "        empty_slice = np.zeros(ImageVolume[0,:,:].shape)\n",
    "        middleslice = ImageVolume[index,:,:]\n",
    "        middlesliceMask = Maskvolume[:,index,:,:]\n",
    "        \n",
    "        if index == 0:\n",
    "            if ImageVolume.shape[0] == 1:\n",
    "                newImageVolume.append(empty_slice)\n",
    "                newImageVolume.append(middleslice)\n",
    "                newImageVolume.append(empty_slice)\n",
    "                newImageVolume = np.stack(newImageVolume, axis=0)\n",
    "            else:\n",
    "                lastslice = ImageVolume[index+1,:,:]\n",
    "                newImageVolume.append(empty_slice)\n",
    "                newImageVolume.append(middleslice)\n",
    "                newImageVolume.append(lastslice)\n",
    "                newImageVolume = np.stack(newImageVolume, axis=0)\n",
    "\n",
    "                \n",
    "        elif index == (ImageVolume.shape[0]-1):\n",
    "            firstslice = ImageVolume[index-1,:,:]\n",
    "            newImageVolume.append(firstslice)\n",
    "            newImageVolume.append(middleslice)\n",
    "            newImageVolume.append(empty_slice)\n",
    "            newImageVolume = np.stack(newImageVolume, axis=0)\n",
    "\n",
    "        else:\n",
    "            firstslice = ImageVolume[index-1,:,:]\n",
    "            lastslice = ImageVolume[index+1,:,:]\n",
    "            newImageVolume.append(firstslice)\n",
    "            newImageVolume.append(middleslice)\n",
    "            newImageVolume.append(lastslice)\n",
    "            newImageVolume = np.stack(newImageVolume, axis=0)\n",
    "\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed_image_volume, transformed_mask_volume = self.transform_volume(newImageVolume, middlesliceMask)\n",
    "            \n",
    "\n",
    "        # return image, mask\n",
    "        return transformed_image_volume, transformed_mask_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da044c57-caba-42dd-a874-e986b1391ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.configuration.config import datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e979541-7089-4cd8-9ba4-cf2e6fd76833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BackGround': 0,\n",
       " 'Bleed-Subdural': 1,\n",
       " 'Scalp-Hematoma': 2,\n",
       " 'Bleed-Others': 3,\n",
       " 'Bleed-Intraventricular': 4,\n",
       " 'Bleed-Epidural': 5,\n",
       " 'Bleed-Contusion': 6,\n",
       " 'Bleed-Hematoma': 7,\n",
       " 'Bleed-Subarachnoid': 8}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0619bb78-a6df-41fc-8c6c-b7c285506343",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDatadict = {\n",
    "    'BackGround': 0,\n",
    "    'Bleed-Subdural': 1,\n",
    "    'Scalp-Hematoma': 2,\n",
    "    'Bleed-Others': 3,\n",
    "    'Bleed-Intraventricular': 4,\n",
    "    'Bleed-Epidural': 5,\n",
    "}\n",
    "reversed_dict = {v: k for k, v in newDatadict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0227bf1-dc47-49b7-824e-de0425d5e53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   BackGround\n",
      "1   Bleed-Subdural\n",
      "2   Scalp-Hematoma\n",
      "3   Bleed-Others\n",
      "4   Bleed-Intraventricular\n",
      "5   Bleed-Epidural\n"
     ]
    }
   ],
   "source": [
    "for key, value in reversed_dict.items():\n",
    "    print(key, \" \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e922dfb8-addf-4d7d-9dd8-56d994bf5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 32\n",
    "height = 512\n",
    "width = 512\n",
    "inputs = np.zeros((1, depth, height , width))\n",
    "targets = np.zeros((1, depth, height , width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b9f311d-1d17-496f-a7c9-608e8d552c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 512, 512)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50caf10a-9e3b-42a6-9050-36adb47a2a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 512, 512)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "83609cb3-3f7d-443c-bcb8-3ef2decd971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BHSD_3D(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, datadict=newDatadict):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        self.series = os.listdir(mask_dir)\n",
    "        self.datadict = datadict\n",
    "        reversed_dict = {v: k for k, v in datadict.items()}\n",
    "        self.reversed_dict = reversed_dict\n",
    "\n",
    "    def transform_volume(self, image_volume, mask_volume):\n",
    "        transformed = self.transform(\n",
    "                image=image_volume, \n",
    "                mask=mask_volume\n",
    "            )\n",
    "        images = transformed['image']\n",
    "        masks = transformed['mask'].permute(2, 0, 1)\n",
    "        return images , masks\n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        nii_segementation = nib.load(os.path.join(self.mask_dir, self.images[index]))\n",
    "        nii_image = nib.load(os.path.join(self.image_dir, self.images[index]))\n",
    "        \n",
    "        # Get the image data as a NumPy array\n",
    "        image_data = nii_image.get_fdata()\n",
    "        segementation_data = nii_segementation.get_fdata()\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed_image_volume, transformed_mask_volume = self.transform_volume(image_data, segementation_data)\n",
    "\n",
    "        transformed_image_volume = transformed_image_volume.unsqueeze(0)\n",
    "        transformed_mask_volume = transformed_mask_volume.unsqueeze(0)\n",
    "        return transformed_image_volume, transformed_mask_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb4f6938-938b-41d3-baed-d0822bc5bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dddb8bbc-1956-48b8-a7c5-74cfea6a4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = r\"C:\\Users\\Rishabh\\Downloads\\label_192\\label_192\"\n",
    "mask_dir = os.path.join(Dir, 'ground truths')\n",
    "image_dir = os.path.join(Dir, 'images')\n",
    "data = BHSD_3D(image_dir, mask_dir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8d244473-1bc8-4718-a75f-c0e85078b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, segementation_data = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f664c2b9-9d2e-4ca7-addb-6acd3f5af14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 256, 256]), torch.Size([1, 28, 256, 256]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape , segementation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0685af52-9041-4bf7-a6ee-439c689223ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def custom_collate(batch):\n",
    "    max_depth = 0\n",
    "    for x,y in batch:\n",
    "        max_depth = max(max_depth, x.shape[1])\n",
    "        # print(x.shape, ' ', y.shape)\n",
    "\n",
    "    newImageVolume = []\n",
    "    newMaskVolume = []\n",
    "    for i in range(len(batch)):\n",
    "        remmaining_slice = max_depth - batch[i][0].shape[1]\n",
    "        # print(remmaining_slice)\n",
    "        if remmaining_slice > 0:\n",
    "            empty_slice = torch.zeros((1,remmaining_slice,batch[i][0].shape[2], batch[i][0].shape[3]))\n",
    "            newImageVolume.append(torch.cat((batch[i][0], empty_slice), dim=1))\n",
    "            newMaskVolume.append(torch.cat((batch[i][1], empty_slice), dim=1))\n",
    "        else:\n",
    "            newImageVolume.append(batch[i][0])\n",
    "            newMaskVolume.append(batch[i][1])\n",
    "    \n",
    "\n",
    "    newImageVolume = torch.stack(newImageVolume, dim=0)\n",
    "    newMaskVolume = torch.stack(newMaskVolume, dim=0)\n",
    "\n",
    "    return newImageVolume, newMaskVolume\n",
    "            \n",
    "            \n",
    "    # print(image_volume.shape, \"  \", mask_volume.shape)\n",
    "    # print(\"hii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "75d3f14a-6f03-4707-976c-e135b9916f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    data,\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3f9cf16a-3804-4db3-987a-5ab1bf14b2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 42, 256, 256])    torch.Size([4, 1, 42, 256, 256])\n",
      "torch.Size([4, 1, 32, 256, 256])    torch.Size([4, 1, 32, 256, 256])\n",
      "torch.Size([4, 1, 32, 256, 256])    torch.Size([4, 1, 32, 256, 256])\n",
      "torch.Size([4, 1, 34, 256, 256])    torch.Size([4, 1, 34, 256, 256])\n",
      "torch.Size([4, 1, 40, 256, 256])    torch.Size([4, 1, 40, 256, 256])\n",
      "torch.Size([4, 1, 32, 256, 256])    torch.Size([4, 1, 32, 256, 256])\n",
      "torch.Size([4, 1, 34, 256, 256])    torch.Size([4, 1, 34, 256, 256])\n",
      "torch.Size([4, 1, 40, 256, 256])    torch.Size([4, 1, 40, 256, 256])\n",
      "torch.Size([4, 1, 36, 256, 256])    torch.Size([4, 1, 36, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m  \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[163]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mBHSD_3D.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     34\u001b[39m segementation_data = nii_segementation.get_fdata()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     transformed_image_volume, transformed_mask_volume = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegementation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m transformed_image_volume = transformed_image_volume.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     40\u001b[39m transformed_mask_volume = transformed_mask_volume.unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[163]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mBHSD_3D.transform_volume\u001b[39m\u001b[34m(self, image_volume, mask_volume)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform_volume\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_volume, mask_volume):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     transformed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_volume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_volume\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     images = transformed[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     20\u001b[39m     masks = transformed[\u001b[33m'\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m'\u001b[39m].permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\albumentations\\core\\composition.py:496\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **data)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocess(data)\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28mself\u001b[39m._track_transform_params(t, data)\n\u001b[32m    498\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.check_data_post_transform(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:176\u001b[39m, in \u001b[36mBasicTransform.__call__\u001b[39m\u001b[34m(self, force_apply, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deterministic:\n\u001b[32m    175\u001b[39m         kwargs[\u001b[38;5;28mself\u001b[39m.save_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] = deepcopy(params)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\albumentations\\core\\transforms_interface.py:200\u001b[39m, in \u001b[36mBasicTransform.apply_with_params\u001b[39m\u001b[34m(self, params, *args, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._key2func \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    198\u001b[39m     target_function = \u001b[38;5;28mself\u001b[39m._key2func[key]\n\u001b[32m    199\u001b[39m     res[key] = ensure_contiguous_output(\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         target_function(\u001b[43mensure_contiguous_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m, **params),\n\u001b[32m    201\u001b[39m     )\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     res[key] = arg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\albumentations\\core\\utils.py:289\u001b[39m, in \u001b[36mensure_contiguous_output\u001b[39m\u001b[34m(arg)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mensure_contiguous_output\u001b[39m(arg: np.ndarray | Sequence[np.ndarray]) -> np.ndarray | \u001b[38;5;28mlist\u001b[39m[np.ndarray]:\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, np.ndarray):\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m         arg = np.ascontiguousarray(arg)\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Sequence):\n\u001b[32m    291\u001b[39m         arg = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(ensure_contiguous_output, arg))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print(inputs.shape, '  ', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5a82266d-f24a-4d50-810d-5e95146f4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(image, mask, name):\n",
    "    gray_image = image\n",
    "    binary_mask = mask\n",
    "    \n",
    "    gray_norm = gray_image / 255.0\n",
    "\n",
    "    # Create an RGB image with grayscale as background\n",
    "    overlay = np.stack([gray_norm, gray_norm, gray_norm], axis=-1)\n",
    "    \n",
    "    # Define lighter colors for each class (0-8)\n",
    "    colors = {\n",
    "        1: [1.0, 0.6, 0.6],   # Light Red\n",
    "        2: [0.6, 1.0, 0.6],   # Light Green\n",
    "        3: [0.6, 0.6, 1.0],   # Light Blue\n",
    "        4: [1.0, 1.0, 0.6],   # Light Yellow\n",
    "        5: [1.0, 0.6, 1.0],   # Light Magenta\n",
    "        6: [0.6, 1.0, 1.0],   # Light Cyan\n",
    "        7: [0.8, 0.7, 1.0],   # Light Purple\n",
    "        8: [1.0, 0.8, 0.6]    # Light Orange\n",
    "    }\n",
    "    \n",
    "    # Create an RGB mask initialized with zeros\n",
    "    mask_rgb = np.zeros_like(overlay)\n",
    "\n",
    "    \n",
    "    # Assign colors based on binary_mask values\n",
    "    for value, color in colors.items():\n",
    "        mask_rgb[binary_mask == value] = color\n",
    "    \n",
    "    # Define transparency level\n",
    "    alpha = 0.4  # Transparency level (0-1)\n",
    "    \n",
    "    # Blend grayscale image with the colored mask\n",
    "    blended = overlay * (1 - alpha) + mask_rgb * alpha\n",
    "    blended = (blended*255).astype(np.uint8)\n",
    "    image = Image.fromarray(blended)\n",
    "    index = len(os.listdir('Predictions'))+1\n",
    "    image.save(f'Predictions/output_{name}_{index}.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ddb1bb85-036d-4946-8bd8-69fa1d214e09",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m index = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_slice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mBHSD_3D.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     30\u001b[39m nii_image = nib.load(os.path.join(\u001b[38;5;28mself\u001b[39m.image_dir, \u001b[38;5;28mself\u001b[39m.images[index]))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Get the image data as a NumPy array\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m image_data = \u001b[43mnii_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m segementation_data = nii_segementation.get_fdata()\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\nibabel\\dataobj_images.py:374\u001b[39m, in \u001b[36mDataobjImage.get_fdata\u001b[39m\u001b[34m(self, caching, dtype)\u001b[39m\n\u001b[32m    370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fdata_cache\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m data = np.asanyarray(\u001b[38;5;28mself\u001b[39m._dataobj, dtype=dtype)\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m caching == \u001b[33m'\u001b[39m\u001b[33mfill\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mself\u001b[39m._fdata_cache = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\nibabel\\arrayproxy.py:454\u001b[39m, in \u001b[36mArrayProxy.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    434\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m    436\u001b[39m \u001b[33;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m \u001b[33;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    456\u001b[39m         arr = arr.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\nibabel\\arrayproxy.py:421\u001b[39m, in \u001b[36mArrayProxy._get_scaled\u001b[39m\u001b[34m(self, dtype, slicer)\u001b[39m\n\u001b[32m    419\u001b[39m     scl_inter = scl_inter.astype(use_dtype)\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m scaled = apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    423\u001b[39m     scaled = scaled.astype(np.promote_types(scaled.dtype, dtype), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\nibabel\\arrayproxy.py:391\u001b[39m, in \u001b[36mArrayProxy._get_unscaled\u001b[39m\u001b[34m(self, slicer)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m._shape, \u001b[38;5;28;01mFalse\u001b[39;00m) == canonical_slicers(\n\u001b[32m    388\u001b[39m     (), \u001b[38;5;28mself\u001b[39m._shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    389\u001b[39m ):\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[32m    401\u001b[39m         fileobj,\n\u001b[32m    402\u001b[39m         slicer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    407\u001b[39m         lock=\u001b[38;5;28mself\u001b[39m._lock,\n\u001b[32m    408\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\nibabel\\volumeutils.py:467\u001b[39m, in \u001b[36marray_from_file\u001b[39m\u001b[34m(shape, in_dtype, infile, offset, order, mmap)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[33m'\u001b[39m\u001b[33mreadinto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    466\u001b[39m     data_bytes = \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     n_read = \u001b[43minfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m     needs_copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\gzip.py:301\u001b[39m, in \u001b[36mGzipFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merrno\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno.EBADF, \u001b[33m\"\u001b[39m\u001b[33mread() on write-only GzipFile object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer.read(size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\gzip.py:507\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[32m    505\u001b[39m buf = \u001b[38;5;28mself\u001b[39m._fp.read(io.DEFAULT_BUFFER_SIZE)\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m uncompress = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail != \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m._fp.prepend(\u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x, y in data:\n",
    "    for i in range(x.shape[0]):\n",
    "        image_slice = x[i,:,:]\n",
    "        mask_slice = y[i,:,:]\n",
    "        if len(np.unique(mask_slice)) > 1:\n",
    "            save_prediction(image_slice*255, mask_slice, name = str(index))\n",
    "\n",
    "    index =  index + 1\n",
    "            \n",
    "    # print(x.shape,\" \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b976603-0e9c-4171-adc7-cde04dd95e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
