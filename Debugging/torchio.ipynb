{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af38eba-5d13-4081-992b-a70c8e034bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07113524-28ea-4aa5-a5c6-d6ca27762b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_4d = torch.rand(4, 100, 100, 100)\n",
    "subject_a = tio.Subject(\n",
    "    t1=tio.ScalarImage(tensor=tensor_4d),\n",
    "    label=tio.LabelMap(tensor=(tensor_4d > 0.5)),\n",
    "    diagnosis='negative',\n",
    ")\n",
    "\n",
    "tensor_4d = torch.rand(5, 100, 100, 100)\n",
    "subject_b = tio.Subject(\n",
    "    t1=tio.ScalarImage(tensor=tensor_4d),\n",
    "    label=tio.LabelMap(tensor=(tensor_4d > 0.5)),\n",
    "    diagnosis='negative',\n",
    ")\n",
    "\n",
    "tensor_4d = torch.rand(7, 100, 100, 100)\n",
    "subject_c = tio.Subject(\n",
    "    t1=tio.ScalarImage(tensor=tensor_4d),\n",
    "    label=tio.LabelMap(tensor=(tensor_4d > 0.5)),\n",
    "    diagnosis='negative',\n",
    ")\n",
    "\n",
    "subjects_list = [subject_a, subject_b, subject_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50548ffd-318a-40be-89c9-2be60d20acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = tio.RescaleIntensity(out_min_max=(0, 1))\n",
    "\n",
    "# As RandomAffine is faster then RandomElasticDeformation, we choose to\n",
    "# apply RandomAffine 80% of the times and RandomElasticDeformation the rest\n",
    "# Also, there is a 25% chance that none of them will be applied\n",
    "spatial = tio.OneOf({\n",
    "        tio.RandomAffine(): 0.8,\n",
    "        tio.RandomElasticDeformation(): 0.2,\n",
    "    },\n",
    "    p=0.75,\n",
    ")\n",
    "\n",
    "# Transforms can be composed as in torchvision.transforms\n",
    "transforms = [rescale, spatial]\n",
    "transform = tio.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2930f51b-42f3-4da0-aba1-14645787b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dataset = tio.SubjectsDataset(subjects_list, transform=transform)\n",
    "\n",
    "# Images are processed in parallel thanks to a SubjectsLoader\n",
    "# (which inherits from torch.utils.data.DataLoader)\n",
    "training_loader = tio.SubjectsLoader(\n",
    "    subjects_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2384f57-bc52-43d7-af8b-2030c26f7694",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 36, in _collate\n    collated_value = _stack([subject[key] for subject in subjects])\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 58, in _stack\n    collated_dict[key] = _stack([element[key] for element in x])\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 51, in _stack\n    return torch.stack(x, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [5, 100, 100, 100] at entry 0 and [4, 100, 100, 100] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubjects_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mt1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1505\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\_utils.py:733\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 36, in _collate\n    collated_value = _stack([subject[key] for subject in subjects])\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 58, in _stack\n    collated_dict[key] = _stack([element[key] for element in x])\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Rishabh\\anaconda3\\envs\\3D_Unet_Bleed\\Lib\\site-packages\\torchio\\data\\loader.py\", line 51, in _stack\n    return torch.stack(x, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [5, 100, 100, 100] at entry 0 and [4, 100, 100, 100] at entry 1\n"
     ]
    }
   ],
   "source": [
    "for subjects_batch in training_loader:\n",
    "    inputs = subjects_batch['t1'][tio.DATA]\n",
    "    target = subjects_batch['label'][tio.DATA]\n",
    "    print('inputs:-',inputs.shape)\n",
    "    print('target:-',target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f09ff9-06a1-4c60-ba33-7d02aa5600f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
