{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5e9a41-695c-446b-b2ec-573c0d2ce054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from src.configuration.config import datadict, TrainingDir\n",
    "from src.Dataset.dataset import CustomDatasetHW, CustomDatasetHWD, CustomDataset, CustomDatasetHW_new, CustomDatasetHW_validation\n",
    "from src.utils.losses import BCEDiceLoss, DiceLoss, GeneralizedDiceLoss, WeightedCrossEntropyLoss, WeightedSmoothL1Loss\n",
    "from src.configuration.config import IMAGE_HEIGHT, IMAGE_WIDTH\n",
    "from src.utils.utils import custom_collate, custom_collate_Variable_HW\n",
    "from src.Models.D_UNet import UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d618c19f-652a-422b-ab18-3af8a12aa455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DunetModel = UNet3D(in_channels=1, out_channels=1).to(device)\n",
    "checkpointpath = r\"C:\\Users\\Rishabh\\Documents\\3D_Unet_Bleed\\model_checkpoint.pth\"\n",
    "DunetModel.load_state_dict(torch.load(checkpointpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba099e1-d1e0-4405-8750-424984707967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'Inference.ipynb',\n",
       " 'main.py',\n",
       " 'model_checkpoint.pth',\n",
       " 'Predictions',\n",
       " 'requirements.txt',\n",
       " 'src',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r\"C:\\Users\\Rishabh\\Documents\\3D_Unet_Bleed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e18cab2-274b-4652-a55d-ad76c5db6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "327e5db1-ae44-4668-8524-24cc0373116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Images', 'Masks']\n"
     ]
    }
   ],
   "source": [
    "ImagesDir = os.path.join(TrainingDir, 'Images')\n",
    "MasksDir = os.path.join(TrainingDir, 'Masks')\n",
    "print(os.listdir(TrainingDir))\n",
    "# data1 = CustomDatasetHW(ImagesDir, MasksDir, transform=train_transform)\n",
    "data = CustomDatasetHW_validation(ImagesDir, MasksDir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fa9a82-d199-421b-b039-1d7947070d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(\n",
    "    data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c569ada-f93a-424b-9df1-b9bf8b38eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(image, mask):\n",
    "    gray_image = image\n",
    "    binary_mask = mask\n",
    "    \n",
    "    gray_norm = gray_image / 255.0\n",
    "\n",
    "    # Create an RGB image with grayscale as background\n",
    "    overlay = np.stack([gray_norm, gray_norm, gray_norm], axis=-1)\n",
    "    \n",
    "    # Define lighter colors for each class (0-8)\n",
    "    colors = {\n",
    "        1: [1.0, 0.6, 0.6],   # Light Red\n",
    "        2: [0.6, 1.0, 0.6],   # Light Green\n",
    "        3: [0.6, 0.6, 1.0],   # Light Blue\n",
    "        4: [1.0, 1.0, 0.6],   # Light Yellow\n",
    "        5: [1.0, 0.6, 1.0],   # Light Magenta\n",
    "        6: [0.6, 1.0, 1.0],   # Light Cyan\n",
    "        7: [0.8, 0.7, 1.0],   # Light Purple\n",
    "        8: [1.0, 0.8, 0.6]    # Light Orange\n",
    "    }\n",
    "    \n",
    "    # Create an RGB mask initialized with zeros\n",
    "    mask_rgb = np.zeros_like(overlay)\n",
    "\n",
    "    \n",
    "    # Assign colors based on binary_mask values\n",
    "    for value, color in colors.items():\n",
    "        mask_rgb[binary_mask == value] = color\n",
    "    \n",
    "    # Define transparency level\n",
    "    alpha = 0.4  # Transparency level (0-1)\n",
    "    \n",
    "    # Blend grayscale image with the colored mask\n",
    "    blended = overlay * (1 - alpha) + mask_rgb * alpha\n",
    "    blended = (blended*255).astype(np.uint8)\n",
    "    image = Image.fromarray(blended)\n",
    "    index = len(os.listdir('Predictions'))+1\n",
    "    image.save(f'Predictions/output_{index}.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66333f-d34f-479e-ae38-77acb8a07424",
   "metadata": {},
   "outputs": [],
   "source": [
    "DunetModel.eval()\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = DunetModel(inputs)\n",
    "    print(output.shape)\n",
    "\n",
    "\n",
    "    # inputs = np.array(inputs)\n",
    "    # targets = np.array(targets)\n",
    "    \n",
    "    # for batch in range(inputs.shape[0]):\n",
    "    #     for sli in range(inputs.shape[2]):\n",
    "            \n",
    "    #         gray_image = inputs[batch, 0, sli, :, :]*255\n",
    "    #         binary_mask = targets[batch, 0, sli, :, :]\n",
    "            # print('gray_image:-',np.unique(gray_image))\n",
    "            # # print('binary_mask:-',np.unique(binary_mask))\n",
    "            # if len(np.unique(binary_mask))>1:\n",
    "            #     # print('binary_mask:-',np.unique(binary_mask))\n",
    "            #     save_prediction(gray_image, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb96323c-6a8b-43e3-99ab-421dda404bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.216239243324311492486775007119878849305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_2736\\1973924460.py:17: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  output = np.array(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107395\n",
      "Batch 0: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.874750920676985942236560559012010376830\n",
      "55903\n",
      "Batch 1: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.327971212165492878990090645563463447694\n",
      "52497\n",
      "Batch 2: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.812609565055494479265790573472977615559\n",
      "75469\n",
      "Batch 3: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.963853606161210352739966258030989557592\n",
      "79005\n",
      "Batch 4: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.387503757565414440314154621408994040708\n",
      "103584\n",
      "Batch 5: Output Shape: (1, 1, 8, 128, 128)\n",
      "2.25.255390386701589077552528917500107662799\n",
      "95878\n",
      "Batch 6: Output Shape: (1, 1, 8, 128, 128)\n",
      "1.2.826.0.1.3680043.10.511.3.50319555245010760304192407653470925\n",
      "78805\n",
      "Batch 7: Output Shape: (1, 1, 8, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Ensure model is in evaluation mode\n",
    "DunetModel.eval()\n",
    "\n",
    "# Iterate through training data\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    # Ensure inputs and targets are on the same device and data type\n",
    "    inputs = inputs.to(device, dtype=torch.float32)\n",
    "    # targets = targets.to(device, dtype=torch.float32)\n",
    "    # print(inputs[:,:,:10,:,:].shape)\n",
    "    inputs = inputs[:,:,:8,:128,:128]\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        output = DunetModel(inputs)\n",
    "\n",
    "    output = output.cpu()\n",
    "    output = np.array(output)\n",
    "    print(len(np.unique(output)))\n",
    "    print(np.min(np.unique(output)))\n",
    "    print(np.max(np.unique(output)))\n",
    "    \n",
    "    \n",
    "\n",
    "    # print(np.unique(output))\n",
    "\n",
    "    # Print output shape\n",
    "    print(f\"Batch {batch_idx}: Output Shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7b532-75a7-4484-b83a-edeec1d8c163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
