{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41de05fe-3d75-4808-aad2-7066221eb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from src.configuration.config import datadict, TrainingDir\n",
    "from src.Dataset.dataset import CustomDatasetHW, CustomDatasetHWD, CustomDataset, CustomDatasetHW_new, CustomDatasetHW_validation\n",
    "from src.utils.losses import BCEDiceLoss, DiceLoss, GeneralizedDiceLoss, WeightedCrossEntropyLoss, WeightedSmoothL1Loss\n",
    "from src.configuration.config import IMAGE_HEIGHT, IMAGE_WIDTH\n",
    "from src.utils.utils import custom_collate, custom_collate_Variable_HW\n",
    "from src.Models.D_UNet import UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aeb4f4e-10a3-49eb-b97e-5bba1ff60d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Rotate(limit=35, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.1),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182dfbf0-62e6-465c-a24a-a9d2127482e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DunetModel = UNet3D(in_channels=1, out_channels=1).to(device)\n",
    "# lossfun = GeneralizedDiceLoss()\n",
    "lossfun = GeneralizedDiceLoss(normalization=\"softmax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc38b35-9b93-4cb6-89d4-d1153cbe7fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Images', 'Masks']\n"
     ]
    }
   ],
   "source": [
    "ImagesDir = os.path.join(TrainingDir, 'Images')\n",
    "MasksDir = os.path.join(TrainingDir, 'Masks')\n",
    "print(os.listdir(TrainingDir))\n",
    "data1 = CustomDatasetHW(ImagesDir, MasksDir, transform=train_transform)\n",
    "data2 = CustomDatasetHW_validation(ImagesDir, MasksDir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d020cbc-13a7-4106-a6a4-cde6e91a7e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 152, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d71da-ef4d-4c60-b3c1-877671945c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b602f6-5e31-470e-8137-61afbc346026",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(\n",
    "    data2,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate,\n",
    ")\n",
    "# for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#     inputs, targets = inputs.to(device), targets.to(device)\n",
    "#     output = DunetModel(inputs)\n",
    "#     loss = lossfun(output, targets)\n",
    "#     print(loss)\n",
    "#     # print(output.shape)\n",
    "#     # print(output.dtype)\n",
    "#     # print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac38c09-fbb4-4f13-9541-98f3bf5557fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628a212-c7b9-48d3-8186-f814a29478eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DunetModel.eval()\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    inputs = np.array(inputs.cpu())\n",
    "    targets = np.array(targets.cpu())\n",
    "    print(inputs.shape)\n",
    "    print(targets.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eb6e8-8b52-420d-90c4-b98b89a80bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    ImageVolume, Maskvolume = data[i]\n",
    "    print(ImageVolume.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef2f0e-ef58-4112-8a3d-1b7fc5c88fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    ImageVolume, Maskvolume = data[i]\n",
    "    ImageVolume = np.array(ImageVolume)\n",
    "    Maskvolume = np.array(Maskvolume)\n",
    "    print(np.unique(Maskvolume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0371e2-eb02-4a15-8bab-3179702bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume, Maskvolume = data[2]\n",
    "ImageVolume = np.array(ImageVolume)\n",
    "Maskvolume = np.array(Maskvolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cb850-099e-4ee8-aebb-64f08aee0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Maskvolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364dad8-ca06-4454-a7e1-9d7aa0c936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume.shape , Maskvolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb47712-a143-43f7-a0a7-27cc0679c1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff3082-7409-46a8-b778-37b7c28b96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73c876-b720-4ef4-975b-d7478141b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Models.D_UNet import UNet3D\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DunetModel = UNet3D(in_channels=1, out_channels=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b85aa-6d80-47bb-a17d-4a3763e7b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor of shape (1, 1, 2, 16, 16) filled with random values\n",
    "ImageVolume = torch.rand(2, 1, 12, 64, 64)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af931d-bca0-4be3-895c-7a5e7903530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert NumPy array to PyTorch tensor\n",
    "# ImageVolume = torch.tensor(ImageVolume, dtype=torch.float32)\n",
    "\n",
    "# Move to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    ImageVolume = ImageVolume.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = DunetModel(ImageVolume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e915c-945f-4b06-87a2-dd8423e42e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3710d-2e59-4dcf-9c25-658f1f490279",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume, Maskvolume = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302326ab-eda9-4a9a-942d-e52e74c4b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageVolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b7283-897b-42d0-83ca-057a2aab2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maskvolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16239f91-3ae8-42f8-aa7a-438f2cd9947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(Maskvolume[:,1,:,:] , axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af4fd9df-5ffe-4238-ad37-71a1cee5aef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.255390386701589077552528917500107662799\n",
      "2.25.963853606161210352739966258030989557592\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "# inputs = np.array(inputs)\n",
    "# targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e3edc1a-abe7-430d-a2ea-2825efbbb198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 157, 512, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3ea781f-7b30-4b52-8d22-a067df43580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets Shape Before One-Hot: torch.Size([2, 1, 157, 512, 512])\n",
      "Loss: 1.0\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Check original shape\n",
    "lossfun = GeneralizedDiceLoss()\n",
    "print(\"Targets Shape Before One-Hot:\", targets.shape)\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "# One-hot encode\n",
    "targets_one_hot = F.one_hot(targets.long(), num_classes=9)  # Shape: (B, C, D, H, W, num_classes)\n",
    "\n",
    "# Permute correctly (Move num_classes to the channel dimension)\n",
    "targets_one_hot = targets_one_hot.permute(0, 5, 1, 2, 3, 4).float()  # Shape: (B, num_classes, C, D, H, W)\n",
    "\n",
    "# Compute loss\n",
    "loss = lossfun(targets_one_hot, targets_one_hot)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# Convert to NumPy and check unique values\n",
    "targets_one_hot_np = targets_one_hot.cpu().numpy()  # Use .cpu() to move tensor to NumPy\n",
    "print(np.unique(targets_one_hot_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35e225-3f62-4355-bd41-ed0a8d7d0874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(inputs.shape[2]):\n",
    "    print(i,\":-\",len(np.unique(inputs[1,0,i,:,:])),  \":-\"  , len(np.unique(targets[1,0,i,:,:]))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7917f69-5104-4f6c-bbd8-3cd2f75d1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad33fb19-fbd2-4ebd-92ea-639c0b8cec99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m slice1 = \u001b[32m102\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Generate dummy data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m gray_image = \u001b[43minputs\u001b[49m[\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, cat, :, :]\n\u001b[32m     10\u001b[39m binary_mask = targets[\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, cat, :, :]\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(np.unique(binary_mask))\n",
      "\u001b[31mNameError\u001b[39m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "cat = 141\n",
    "slice1 = 102\n",
    "\n",
    "# Generate dummy data\n",
    "gray_image = inputs[1, 0, cat, :, :]\n",
    "binary_mask = targets[1, 0, cat, :, :]\n",
    "print(np.unique(binary_mask))\n",
    "\n",
    "# Normalize grayscale image to range 0-1\n",
    "gray_norm = gray_image / 255.0\n",
    "\n",
    "# Create an RGB image with grayscale as background\n",
    "overlay = np.stack([gray_norm, gray_norm, gray_norm], axis=-1)\n",
    "\n",
    "# Define lighter colors for each class (0-8)\n",
    "colors = {\n",
    "    0: [0.9, 0.9, 0.9],   # Light Gray\n",
    "    1: [1.0, 0.6, 0.6],   # Light Red\n",
    "    2: [0.6, 1.0, 0.6],   # Light Green\n",
    "    3: [0.6, 0.6, 1.0],   # Light Blue\n",
    "    4: [1.0, 1.0, 0.6],   # Light Yellow\n",
    "    5: [1.0, 0.6, 1.0],   # Light Magenta\n",
    "    6: [0.6, 1.0, 1.0],   # Light Cyan\n",
    "    7: [0.8, 0.7, 1.0],   # Light Purple\n",
    "    8: [1.0, 0.8, 0.6]    # Light Orange\n",
    "}\n",
    "\n",
    "# Create an RGB mask initialized with zeros\n",
    "mask_rgb = np.zeros_like(overlay)\n",
    "\n",
    "# Assign colors based on binary_mask values\n",
    "for value, color in colors.items():\n",
    "    mask_rgb[binary_mask == value] = color\n",
    "\n",
    "# Define transparency level\n",
    "alpha = 0.4  # Transparency level (0-1)\n",
    "\n",
    "# Blend grayscale image with the colored mask\n",
    "blended = overlay * (1 - alpha) + mask_rgb * alpha\n",
    "\n",
    "print(blended.shape)\n",
    "blended = (blended*255).astype(np.uint8)\n",
    "# blended = np.transpose(blended, (2, 0, 1))  # Change shape to (3, 256, 256)\n",
    "image = Image.fromarray(blended)\n",
    "image\n",
    "\n",
    "# Display the result\n",
    "# plt.imshow(blended)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a01431-d51a-4471-b0f3-beabf0b61889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(image, mask):\n",
    "    gray_image = image\n",
    "    binary_mask = mask\n",
    "    \n",
    "    gray_norm = gray_image / 255.0\n",
    "\n",
    "    # Create an RGB image with grayscale as background\n",
    "    overlay = np.stack([gray_norm, gray_norm, gray_norm], axis=-1)\n",
    "    \n",
    "    # Define lighter colors for each class (0-8)\n",
    "    colors = {\n",
    "        1: [1.0, 0.6, 0.6],   # Light Red\n",
    "        2: [0.6, 1.0, 0.6],   # Light Green\n",
    "        3: [0.6, 0.6, 1.0],   # Light Blue\n",
    "        4: [1.0, 1.0, 0.6],   # Light Yellow\n",
    "        5: [1.0, 0.6, 1.0],   # Light Magenta\n",
    "        6: [0.6, 1.0, 1.0],   # Light Cyan\n",
    "        7: [0.8, 0.7, 1.0],   # Light Purple\n",
    "        8: [1.0, 0.8, 0.6]    # Light Orange\n",
    "    }\n",
    "    \n",
    "    # Create an RGB mask initialized with zeros\n",
    "    mask_rgb = np.zeros_like(overlay)\n",
    "\n",
    "    \n",
    "    # Assign colors based on binary_mask values\n",
    "    for value, color in colors.items():\n",
    "        mask_rgb[binary_mask == value] = color\n",
    "    \n",
    "    # Define transparency level\n",
    "    alpha = 0.4  # Transparency level (0-1)\n",
    "    \n",
    "    # Blend grayscale image with the colored mask\n",
    "    blended = overlay * (1 - alpha) + mask_rgb * alpha\n",
    "    blended = (blended*255).astype(np.uint8)\n",
    "    image = Image.fromarray(blended)\n",
    "    index = len(os.listdir('Predictions'))+1\n",
    "    image.save(f'Predictions/output_{index}.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b22829-ed82-4307-b9b2-18505cfef312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37b0070e-4962-4d25-a3bf-3767e184c663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.812609565055494479265790573472977615559\n",
      "2.25.327971212165492878990090645563463447694\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 6 is not equal to len(dims) = 5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# inputs, targets = inputs.to(device), targets.to(device)\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# inputs = np.array(inputs)\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# targets = np.array(targets)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     loss = lossfun(\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m.float(), F.one_hot(targets.long(), num_classes=\u001b[32m9\u001b[39m).permute(\u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m).float())\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[32m      8\u001b[39m     loss = criterion(targets.float(), targets.float())\n",
      "\u001b[31mRuntimeError\u001b[39m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 6 is not equal to len(dims) = 5"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    # inputs, targets = inputs.to(device), targets.to(device)\n",
    "    # inputs = np.array(inputs)\n",
    "    # targets = np.array(targets)\n",
    "    loss = lossfun(F.one_hot(targets, num_classes=9).permute(0, 4, 1, 2, 3).float(), F.one_hot(targets, num_classes=9).permute(0, 4, 1, 2, 3).float())\n",
    "    print(loss)\n",
    "\n",
    "    loss = criterion(targets.float(), targets.float())\n",
    "    print(loss)\n",
    "    # for batch in range(inputs.shape[0]):\n",
    "    #     for sli in range(inputs.shape[2]):\n",
    "            \n",
    "    #         gray_image = inputs[batch, 0, sli, :, :]*255\n",
    "    #         binary_mask = targets[batch, 0, sli, :, :]\n",
    "    #         # print('gray_image:-',np.unique(gray_image))\n",
    "    #         # print('binary_mask:-',np.unique(binary_mask))\n",
    "    #         if len(np.unique(binary_mask))>1:\n",
    "    #             # print('binary_mask:-',np.unique(binary_mask))\n",
    "    #             save_prediction(gray_image, binary_mask)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2335a-3da9-45b4-bfdc-17653a9d846a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
